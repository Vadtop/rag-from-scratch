import os
import requests
import numpy as np
from dotenv import load_dotenv

load_dotenv()  # —á–∏—Ç–∞–µ–º OPENROUTER_API_KEY –∏–∑ .env

API_KEY = os.environ["OPENROUTER_API_KEY"]
BASE_URL = "https://openrouter.ai/api/v1"


# ========== API –§–£–ù–ö–¶–ò–ò ==========
def get_embedding(text):
    """–ü–æ–ª—É—á–∞–µ—Ç embedding —á–µ—Ä–µ–∑ requests"""
    response = requests.post(
        f"{BASE_URL}/embeddings",
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "openai/text-embedding-3-small",
            "input": text
        }
    )
    return response.json()["data"][0]["embedding"]

def get_completion(messages):
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM —á–µ—Ä–µ–∑ requests"""
    response = requests.post(
        f"{BASE_URL}/chat/completions",
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": "openai/gpt-3.5-turbo",
            "messages": messages,
            "temperature": 0
        }
    )
    return response.json()["choices"][0]["message"]["content"]

# ========== CHUNKING ==========
def chunk_text(text, chunk_size=150, overlap=50):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        
        print(f"Chunk {len(chunks)}: start={start}, end={end}, len={len(chunk)}")  # ‚Üê –î–û–ë–ê–í–¨
        
        if chunk.strip():
            chunks.append(chunk)
        
        start += (chunk_size - overlap)
    
    return chunks

# ========== –ó–ê–ì–†–£–ó–ö–ê ==========
def load_documents_with_chunking(folder_path="documents"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —á–∞–Ω–∫–∏"""
    chunks_data = []
    
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            filepath = os.path.join(folder_path, filename)
            
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read().strip()
            
            chunks = chunk_text(content, chunk_size=500, overlap=100)
            
            for i, chunk in enumerate(chunks):
                chunks_data.append({
                    "content": chunk,
                    "source": filename,
                    "chunk_id": i,
                    "total_chunks": len(chunks)
                })
            
            print(f"üìÑ {filename}: {len(chunks)} chunks")
    
    return chunks_data

# ========== COSINE SIMILARITY ==========
def cosine_similarity(vec1, vec2):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

# ========== MAIN ==========
print("üìÇ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å chunking...")
chunks = load_documents_with_chunking()
print(f"‚úÖ –í—Å–µ–≥–æ chunks: {len(chunks)}\n")

print("‚è≥ –°–æ–∑–¥–∞—é embeddings...")
for i, chunk in enumerate(chunks):
    chunk["embedding"] = get_embedding(chunk["content"])
    print(f"  {i+1}/{len(chunks)}", end="\r")
print("\n‚úÖ Embeddings –≥–æ—Ç–æ–≤—ã!\n")

# ========== RAG ==========
def rag_query(query, top_k=3):
    """RAG pipeline"""
    
    # 1. Embedding –∑–∞–ø—Ä–æ—Å–∞
    query_emb = get_embedding(query)
    
    # 2. –ü–æ–∏—Å–∫
    results = []
    for chunk in chunks:
        sim = cosine_similarity(query_emb, chunk["embedding"])
        results.append((chunk, sim))
    
    results.sort(key=lambda x: x[1], reverse=True)
    top_chunks = results[:top_k]
    
    # 3. –ö–æ–Ω—Ç–µ–∫—Å—Ç
    context_parts = []
    for chunk, score in top_chunks:
        context_parts.append(
            f"[{chunk['source']}, chunk {chunk['chunk_id']+1}/{chunk['total_chunks']}]\n{chunk['content']}"
        )
    
    context = "\n\n---\n\n".join(context_parts)
    
    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    prompt = f"""Answer the question based on this context.

Context:
{context}

Question: {query}

Answer (be concise):"""
    
    answer = get_completion([{"role": "user", "content": prompt}])
    
    sources = list(set([chunk['source'] for chunk, _ in top_chunks]))
    
    return {
        "answer": answer,
        "sources": sources,
        "chunks_used": [
            (chunk['source'], chunk['chunk_id']+1, f"{score:.3f}") 
            for chunk, score in top_chunks
        ]
    }

# ========== –¢–ï–°–¢–´ ==========
print("="*60)
print("ü§ñ RAG –°–ò–°–¢–ï–ú–ê –° CHUNKING")
print("="*60)

# –¢–µ—Å—Ç 1
print("\nüìù –í–æ–ø—Ä–æ—Å: How does RAG work?")
result = rag_query("How does RAG work?")
print(f"‚úÖ –û–¢–í–ï–¢:\n{result['answer']}")
print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(result['sources'])}")
print(f"üìä Chunks: {result['chunks_used']}\n")

# –¢–µ—Å—Ç 2
print("üìù –í–æ–ø—Ä–æ—Å: What is Python used for?")
result = rag_query("What is Python used for?")
print(f"‚úÖ –û–¢–í–ï–¢:\n{result['answer']}")
print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(result['sources'])}\n")

print("="*60)
print("‚úÖ RAG —Å chunking —Ä–∞–±–æ—Ç–∞–µ—Ç!")
