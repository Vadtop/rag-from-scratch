from openai import OpenAI
import numpy as np
import os
from dotenv import load_dotenv

load_dotenv()  # –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç OPENROUTER_API_KEY –∏–∑ .env

API_KEY = os.environ["OPENROUTER_API_KEY"]
BASE_URL = "https://openrouter.ai/api/v1"

client = OpenAI(
    api_key=API_KEY,
    base_url=BASE_URL,
)

# –§—É–Ω–∫—Ü–∏—è: –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –≤ –≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª
def get_embedding(text):
    response = client.embeddings.create(
        model="openai/text-embedding-3-small",
        input=text
    )
    return response.data[0].embedding


# –¢–µ—Å—Ç: –±–µ—Ä—ë–º 3 —Ñ—Ä–∞–∑—ã
text1 = "Python is a programming language"
text2 = "Java is a programming language"
text3 = "I love pizza"


# –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ—Ä–∞–∑—ã
emb1 = get_embedding(text1)
emb2 = get_embedding(text2)
emb3 = get_embedding(text3)


# –°–º–æ—Ç—Ä–∏–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å
print(f"–†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞: {len(emb1)}")
print(f"–ü–µ—Ä–≤—ã–µ 5 —á–∏—Å–µ–ª –≤–µ–∫—Ç–æ—Ä–∞: {emb1[:5]}")


# ========== –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ ==========


def cosine_similarity(vec1, vec2):
    """–°—á–∏—Ç–∞–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ (–æ—Ç -1 –¥–æ 1)"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)


# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã
print("\n=== –°–†–ê–í–ù–ï–ù–ò–ï –¢–ï–ö–°–¢–û–í ===")


sim_python_java = cosine_similarity(emb1, emb2)
print(f"Python vs Java: {sim_python_java:.3f}")


sim_python_pizza = cosine_similarity(emb1, emb3)
print(f"Python vs Pizza: {sim_python_pizza:.3f}")


sim_java_pizza = cosine_similarity(emb2, emb3)
print(f"Java vs Pizza: {sim_java_pizza:.3f}")


# ========== –ó–ê–ì–†–£–ó–ö–ê –î–û–ö–£–ú–ï–ù–¢–û–í –ò–ó –§–ê–ô–õ–û–í ==========


def load_documents_from_folder(folder_path="documents"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ .txt —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏"""
    documents = []
    
    print(f"\nüìÇ –ó–∞–≥—Ä—É–∂–∞—é –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ '{folder_path}/'...")
    
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            filepath = os.path.join(folder_path, filename)
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    documents.append({
                        "content": content,
                        "source": filename
                    })
                    print(f"  ‚úÖ {filename}")
    
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(documents)}\n")
    return documents


# ========== –ü–û–ò–°–ö–û–í–ò–ö –ü–û –î–û–ö–£–ú–ï–ù–¢–ê–ú ==========


# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ñ–∞–π–ª–æ–≤
documents = load_documents_from_folder("documents")


print("=== –ë–ê–ó–ê –î–û–ö–£–ú–ï–ù–¢–û–í ===")
for i, doc in enumerate(documents, 1):
    print(f"{i}. [{doc['source']}] {doc['content'][:80]}...")


# –ü–æ–ª—É—á–∞–µ–º embeddings –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–µ–ª–∞–µ—Ç—Å—è 1 —Ä–∞–∑)
print("\n‚è≥ –ü–æ–ª—É—á–∞–µ–º embeddings...")
doc_embeddings = [get_embedding(doc["content"]) for doc in documents]
print("‚úÖ –ì–æ—Ç–æ–≤–æ!")


# –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞
def search(query, top_k=2):
    """–ò—â–µ—Ç top_k –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    print(f"\nüîç –ó–∞–ø—Ä–æ—Å: '{query}'")
    
    # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
    query_emb = get_embedding(query)
    
    # –°—á–∏—Ç–∞–µ–º similarity –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    results = []
    for doc_obj, doc_emb in zip(documents, doc_embeddings):
        sim = cosine_similarity(query_emb, doc_emb)
        results.append((doc_obj, sim))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    results.sort(key=lambda x: x[1], reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top_k
    return results[:top_k]


# –¢–ï–°–¢–´
print("\n" + "="*50)
print("–¢–ï–°–¢ –ü–û–ò–°–ö–û–í–ò–ö–ê")
print("="*50)


# –¢–µ—Å—Ç 1
results = search("Tell me about Python")
for i, (doc_obj, score) in enumerate(results, 1):
    print(f"  {i}. [{score:.3f}] {doc_obj['content'][:60]}... (–∏—Å—Ç–æ—á–Ω–∏–∫: {doc_obj['source']})")


# ============= –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–í–ï–¢–ê –ß–ï–†–ï–ó LLM ================


def generate_answer(query, relevant_docs):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    context = "\n".join([f"- {doc_obj['content']}" for doc_obj, score in relevant_docs])

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º—Ç
    prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç (–∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–¥ –¥–µ–ª—É):"""
    
    # –ó–∞–ø—Ä–æ—Å –∫ LLM —á–µ—Ä–µ–∑ OpenRouter
    response = client.chat.completions.create(
        model="openai/gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": prompt}
        ]
    )
    
    return response.choices[0].message.content


# ========== –ü–û–õ–ù–´–ô RAG (–ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è) ==========


def rag_pipeline(query, top_k=2):
    """–ü–æ–ª–Ω—ã–π RAG: –Ω–∞—Ö–æ–¥–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç"""
    
    print(f"\n{'='*60}")
    print(f"ü§ñ RAG –°–ò–°–¢–ï–ú–ê")
    print(f"{'='*60}")
    print(f"üìù –í–æ–ø—Ä–æ—Å: {query}\n")
    
    # –®–∞–≥ 1: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    print("üîç –ò—â—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
    relevant_docs = search(query, top_k=top_k)
    
    print("\nüìö –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:")
    for i, (doc_obj, score) in enumerate(relevant_docs, 1):
        print(f"  {i}. [{score:.3f}] {doc_obj['content'][:60]}...")
        print(f"      üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {doc_obj['source']}")
    
    # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    print("\nüí≠ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
    answer = generate_answer(query, relevant_docs)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    sources = [doc_obj['source'] for doc_obj, score in relevant_docs]
    sources_text = ", ".join(sources)

    print(f"\n‚úÖ –û–¢–í–ï–¢:\n{answer}")
    print(f"\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources_text}")
    print(f"{'='*60}\n")
    
    return answer


# ========== –¢–ï–°–¢–´ –ü–û–õ–ù–û–ì–û RAG ==========


print("\n\n" + "üöÄ"*30)
print("–¢–ï–°–¢–ò–†–£–ï–ú –ü–û–õ–ù–´–ô RAG")
print("üöÄ"*30 + "\n")


# –¢–µ—Å—Ç 1: –ü—Ä–æ RAG
rag_pipeline("How does RAG work?")


# –¢–µ—Å—Ç 2: –ü—Ä–æ vector DB
rag_pipeline("What are vector databases used for?")


# –¢–µ—Å—Ç 3: –ü—Ä–æ OpenRouter
rag_pipeline("What is OpenRouter?")
